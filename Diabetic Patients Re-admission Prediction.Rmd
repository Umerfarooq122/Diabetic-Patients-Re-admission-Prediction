---
title: "Diabetic Patient ReAdmission Prediction"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)

library(tidyverse)
library(glmnet)
library(mice)
library(psych)
library(pROC)
library(caret)
library(devtools)
library(nnet)
library(MASS)
library(faraway)
library(corrplot)
library(DataExplorer)
library(neuralnet)
library(keras)
library(e1071)
library(tensorflow)
library(class)

```

## **Loading and Cleaning Data:**

```{r message=FALSE, warning=FALSE}
df <- read_csv("https://raw.githubusercontent.com/Umerfarooq122/Diabetic-Patients-Re-admission-Prediction/main/diabetic_data.csv")
```

```{r}
df[df == '?'] <- NA
```


```{r}
colSums(is.na(df))
```

```{r}
sum(duplicated(df$encounter_id))
```


```{r}
df <- df[-c(1,2,6,11,12)]
```

```{r}
str(df)
```

```{r}
colSums(is.na(df))
```


```{r}
set.seed(2)
df <- na.omit(df)
```

```{r}
df[] <- lapply(df, function(x) if(is.character(x)) factor(x) else x)
```

```{r}
df$admission_type_id <- as.factor(df$admission_type_id)
df$discharge_disposition_id <- as.factor(df$discharge_disposition_id)
df$admission_source_id <- as.factor(df$admission_source_id)
```

```{r}
str(df)
```




```{r}
df <- df[-c(35,36,41)]
```

```{r}
df <- df[-c(14,15,16)]
```


```{r}
str(df)
```


## **Data Exploration:** 

```{r}
knitr::kable(describe(df))
```


```{r}
ggplot(df, aes(y = readmitted)) +
  geom_bar() +
  labs(title = "Imbalanced",y = 'Re-Admissions', x = 'Frequency')+theme_bw()
```



```{r warning=FALSE , message=FALSE}
out <- split_columns(df)
plot_histogram(out$continuous)
plot_bar(out$discrete)
```

## **Creating Models:**

### **Multinomial logit model:**


```{r}
set.seed(42)
split <- createDataPartition(df$readmitted, p=.75, list=FALSE)
partial_train <- df[split, ]
validation <- df[ -split, ]
```

```{r}
m1 <- multinom(readmitted~., data = partial_train, maxit = 500)
```

```{r}
#summary(m1)
```

```{r}
pred_class <- predict(m1, newdata = validation[-c(39)], type = "class" )
```

```{r}
mat1 <- confusionMatrix(pred_class, validation$readmitted, 
                        mode = "everything")
```

```{r}
mat1$table
```

```{r}
mat1$byClass
```


### **Reduced Mulitnomial logit model:**

```{r}

m2 <- multinom(readmitted~ race + gender + admission_type_id + num_lab_procedures+ num_medications + num_procedures + number_inpatient + number_outpatient + number_diagnoses + A1Cresult + metformin + glimepiride + glipizide + glyburide + pioglitazone + rosiglitazone + insulin + change + diabetesMed, data = partial_train, maxit = 500)

```

```{r}
pred2_class <- predict(m2, newdata = validation[-c(39)], type = "class")
```

```{r}
mat2 <- confusionMatrix(pred2_class, validation$readmitted, 
                        mode = "everything")
```

```{r}
mat2$table
```

 
## **Downsampling models:** 




 
### **Multinomial Logit:**

#### **Identifying Predictos Using Forward Stepwise Based On AIC Criterion:** 

```{r}
set.seed(42)
split <- createDataPartition(dtrain$Class, p=.75, list=FALSE)
p_train <- dtrain[split, ]
valid <- dtrain[ -split, ]
```

```{r}
model <- multinom(Class ~ 1, data = p_train)
```
```{r}
fit_multinom <- function(variables) {
  formula <- as.formula(paste("Class ~", paste(variables, collapse = " + ")))
  model <- tryCatch(multinom(formula, data = p_train), error = function(e) NULL)
  if (!is.null(model)) {
    return(AIC(model))
  } else {
    return(Inf)  # Return a high AIC if the model cannot be fitted
  }
}
```

```{r}
predictor_variables <- names(p_train[!names(p_train) %in% c("Class")])
```


```{r}
#selected_predictors <- character(0)
#while (length(selected_predictors) < 38) {
#  candidate_predictors <- setdiff(predictor_variables, selected_predictors)
#  aic_values <- sapply(candidate_predictors, function(pred) fit_multinom(c(selected_predictors, pred)))
#  best_predictor <- candidate_predictors[which.min(aic_values)]
#  selected_predictors <- c(selected_predictors, best_predictor)
#}
```


```{r}
#print(selected_predictors)
```


#### **Model:**

```{r}
dtrain <- downSample(x = df[, -39],
                     y = df$readmitted)
```



```{r}
ggplot(dtrain, aes(y = Class)) +
  geom_bar() +
  labs(title = "Balanced",y = 'Re-Admissions', x = 'Frequency')+theme_bw()
```


```{r}
set.seed(42)
split <- createDataPartition(dtrain$Class, p=.75, list=FALSE)
p_train <- dtrain[split, ]
valid <- dtrain[ -split, ]
```


```{r}
m111 <- multinom(Class~., data = p_train, maxit = 500)
```

```{r}
predd_class <- predict(m111, newdata = valid[-c(39)], type = "class")
```

```{r}
mat_sample <- confusionMatrix(predd_class, valid$Class, 
                        mode = "everything")
```

```{r}
mat_sample$table
```

```{r}
mat_sample$byClass
```
### **Reduced multinomial logit:**

```{r warning=FALSE , message=FALSE}
out <- split_columns(dtrain)
plot_histogram(out$continuous)
plot_bar(out$discrete)
```
```{r}
m112 <- multinom(Class~ race + gender + admission_type_id + num_lab_procedures+ num_medications + num_procedures + time_in_hospital + number_inpatient + number_outpatient + number_diagnoses + A1Cresult + metformin + glimepiride + glipizide + glyburide + pioglitazone + rosiglitazone + insulin + change + diabetesMed, data = p_train, maxit = 500)
```


```{r}
predd2_class <- predict(m112, newdata = valid[-c(39)], type = "class")
```

```{r}
mat2_sample <- confusionMatrix(predd2_class, valid$Class, 
                        mode = "everything")
```

```{r}
mat2_sample$byClass
```


### **Multinomial logit With CV:**

```{r}
ctrl <- trainControl(method = 'cv', number = 2)
mcv <- caret::train(Class~ ., data = p_train, method = "multinom", trControl = ctrl)
```

```{r}
predcv_class <- predict(mcv, newdata = valid[-c(39)], type = "raw")
```



```{r}
matcv_sample <- confusionMatrix(predcv_class, valid$Class, 
                        mode = "everything")
```

```{r}
matcv_sample$table
```
```{r}
matcv_sample$byClass
```


## **Coding the data**

```{r warning=FALSE , message=FALSE}
outtr <- split_columns(p_train)
outte <- split_columns(valid)
#plot_histogram(out$continuous)
#plot_bar(out$discrete)
```

```{r}
x_train_continuous <- scale(outtr$continuous)
x_test_continuous <- scale(outte$continuous)
```


```{r}
x_train_categorical <- model.matrix(~., data = outtr$discrete)[, -1]
x_test_categorical <- model.matrix(~., data = outte$discrete)[, -1]
```



```{r}
x_train1 <- cbind(x_train_continuous, x_train_categorical)
x_test1 <- cbind(x_test_continuous, x_test_categorical)

```

```{r}
x_train <- as.matrix(x_train1[,1:126])
y_train <- as.matrix(x_train1[,127:128])
```

```{r}
x_test <- as.matrix(x_test1[,1:126])
y_test <- as.matrix(x_test1[,127:128])
```

```{r}
mat_df <- cbind.data.frame(x_train, class = p_train$Class)
```

```{r}
mat_m1 <- multinom(class~., data = mat_df, maxit=1000)
```


```{r}
mat_pred1 <- predict(mat_m1, newdata = x_test, type = 'class')
```

```{r}
mat_mat <- confusionMatrix(mat_pred1, valid$Class, mode = "everything")
```

```{r}
mat_mat$table
```
```{r}
mat_mat$byClass
```



## **Random Forest:**

```{r warning=FALSE, message=FALSE}
library(randomForest)
set.seed(12)
# Training with Random forest model
modfit.rf <- randomForest(Class~race + gender + admission_type_id + num_lab_procedures+ num_medications + num_procedures + time_in_hospital + number_inpatient + number_outpatient + number_diagnoses + A1Cresult + metformin + glimepiride + glipizide + glyburide + pioglitazone + rosiglitazone + insulin + change + diabetesMed, ntree = 700, data = p_train)

# Predict the testing set with the trained model
predictions2 <- predict(modfit.rf, valid[-c(39)], type = "class")
```


```{r}
# Accuracy and other metrics
rand_mat <- confusionMatrix(predictions2, valid$Class)
```

```{r}
rand_mat$byClass
```


## **Support Vector Machine:**

```{r}
svm_df <- cbind.data.frame(x_train_categorical, outtr$continuous, class = p_train$Class)
```


```{r warning=FALSE, message=FALSE}
svm_model <- svm(class~., data = mat_df, type = "C-classification")

#best_svm_model <- svm_model$best.model

```


```{r}
svm_pred <- predict(svm_model, newdata = x_test, type = "class")
```

```{r}
svm_conmat <- confusionMatrix(svm_pred, valid$Class, mode = "everything")
```

```{r}
svm_conmat$byClass
```

## **KNN:**

```{r}
set.seed(32)
# Number of neighbors
k <- 120

# Perform kNN classification
predicted_classes <- knn(train = x_train, 
                         test = x_test, 
                         cl = mat_df$class, 
                         k = k)

```

```{r}
knn_mat <- confusionMatrix(data = factor(predicted_classes), valid$Class)
```

```{r}
knn_mat$byClass
```
## **Classification Metrics:**

```{r}
final_table <- data.frame(mat1$byClass)
```


```{r}
eval1 <- data.frame(mat1$byClass)
row.names(eval1) <- c("Multinomial (<30)", "Multinomial (>30)", "Multinomial (NO)")

eval2 <- data.frame(mat2$byClass)
row.names(eval2) <- c("Reduced Multinomial (<30)", "Reduced Multinomial (>30)", "Reduced Multinomial (NO)")

eval3 <- data.frame(mat_sample$byClass)
row.names(eval3) <- c("Down Sampled Multinomial (<30)", "Down Sampled Multinomial (>30)", "Down Sampled Multinomial (NO)")

eval4 <- data.frame(mat2_sample$byClass)
row.names(eval4) <- c("Down Sampled Reduced Multinomial (<30)", "Down Sampled Reduced Multinomial (>30)", "Down Sampled Reduced Multinomial (NO)")

eval5 <- data.frame(matcv_sample$byClass)
row.names(eval5) <- c("Multinomial Cross Validated (<30)", "Multinomial Cross Validated (>30)", "Multinomial Cross Validated (NO)")

eval6 <- data.frame(mat_mat$byClass)
row.names(eval6) <- c("Multinomial with Coded Matrix (<30)", "Multinomial with Coded Matrix (>30)", "Multinomial with Coded Matrix (NO)")

eval7 <- data.frame(rand_mat$byClass)
row.names(eval7) <- c("Random Forest (<30)", "Random Forest (>30)", "Random Forest (NO)")

eval8 <- data.frame(knn_mat$byClass)
row.names(eval8) <- c("KNN (<30)", "KNN (>30)", "KNN (NO)")

eval9 <- data.frame(svm_conmat$byClass)
row.names(eval9) <- c("Support Vector Machines (<30)", "Support Vector Machines (>30)", "Support Vector Machines (NO)")
```


```{r}
final_eval <- rbind.data.frame(eval1,eval2, eval3, eval4, eval5,eval6,eval7,eval8, eval9)
```

```{r}
#file <- "/Users/umerfarooq/Desktop/Data 621/Final Project.xlsx"
#write.xlsx(final_eval, file = file, sheetName = "eval", rowNames = TRUE)
```

## **Extra Attempt:**

## **Simple Neural Network:**

```{r}
#set.seed(42)
#split <- createDataPartition(dtrain$Class, p=.75, list=FALSE)
#d_train <- dtrain[split, ]
#valid <- dtrain[ -split, ]
```

```{r}
#colnames(x_test) <- paste0('X',1:ncol(x_test))
```

```{r}
#colnames(mat_df) <- paste0('X',1:ncol(mat_df))
```

```{r}
#FORMULA <- X127~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15+X16+X17

```


```{r}
#nn_model <- neuralnet(
#  FORMULA,
#  data = mat_df,
#  hidden = c(32,16,3),
  
#  err.fct = "ce",  # Cross-entropy loss for multiclass classification
#  act.fct = "logistic"
#)
```


```{r}
#plot(nn_model)
```

```{r}
#pred_nn <- predict(nn_model, newdata = x_test)
```

```{r}
#class_nn <- max.col(pred_nn, ties.method = "first")
#class_label <- c("<30",">30","NO")
#classpred_nn <- class_label[class_nn]
```


```{r}
#conmat_nn <- confusionMatrix(data = factor(classpred_nn), valid$Class)
```

```{r}
#conmat_nn$byClass
```






























